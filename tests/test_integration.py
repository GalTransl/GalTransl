"""
å®‰å…¨å†™å…¥æœºåˆ¶é›†æˆæµ‹è¯• - å¼‚å¸¸æƒ…å†µä¸‹çš„æ•°æ®å®Œæ•´æ€§éªŒè¯
æµ‹è¯•åœ¨å„ç§å¼‚å¸¸æƒ…å†µä¸‹æ•°æ®çš„å®Œæ•´æ€§ä¿æŠ¤
"""

import asyncio
import tempfile
import json
import os
import signal
import time
import shutil
from pathlib import Path
from unittest.mock import Mock, patch, AsyncMock
from contextlib import asynccontextmanager
import sys
sys.path.insert(0, '/data/workspace/GalTransl')

from GalTransl.SafeWrite import AtomicFileWriter, DataValidator, BackupManager
from GalTransl.Cache import save_transCache_to_json, _save_with_safe_write
from GalTransl.CSentense import CTransList, CSentense


class IntegrationTestSuite:
    """é›†æˆæµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.test_dir = None
        self.results = []
        
    async def setup(self):
        """æµ‹è¯•ç¯å¢ƒè®¾ç½®"""
        self.test_dir = Path(tempfile.mkdtemp())
        print(f"æµ‹è¯•ç›®å½•: {self.test_dir}")
        
    async def teardown(self):
        """æµ‹è¯•ç¯å¢ƒæ¸…ç†"""
        if self.test_dir and self.test_dir.exists():
            shutil.rmtree(self.test_dir)
    
    def create_test_cache_data(self, count=100):
        """åˆ›å»ºæµ‹è¯•ç¼“å­˜æ•°æ®"""
        cache_data = []
        for i in range(count):
            cache_obj = {
                "index": i,
                "name": f"è§’è‰²{i}",
                "pre_jp": f"æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ{i}",
                "post_jp": f"æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ{i}",
                "pre_zh": f"ä¸­æ–‡æ–‡æœ¬{i}",
                "proofread_zh": "",
                "trans_by": "test_engine",
                "proofread_by": "",
                "trans_conf": 0,
                "doub_content": "",
                "unknown_proper_noun": ""
            }
            cache_data.append(cache_obj)
        return cache_data
    
    def create_mock_project_config(self, safe_write_enabled=True):
        """åˆ›å»ºæ¨¡æ‹Ÿé¡¹ç›®é…ç½®"""
        mock_config = Mock()
        mock_config.getSafeWriteConfig.return_value = {
            'enable_safe_write': safe_write_enabled,
            'write_verification': True,
            'enable_backup': True,
            'backup_retention_count': 3,
            'temp_file_cleanup': True,
            'write_timeout_seconds': 30
        }
        return mock_config
    
    async def test_normal_operation(self):
        """æµ‹è¯•æ­£å¸¸æ“ä½œ"""
        print("\n=== æµ‹è¯•æ­£å¸¸æ“ä½œ ===")
        
        cache_file = self.test_dir / "normal_test.json"
        cache_data = self.create_test_cache_data(50)
        project_config = self.create_mock_project_config()
        
        try:
            await _save_with_safe_write(cache_data, str(cache_file), project_config)
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨ä¸”å†…å®¹æ­£ç¡®
            assert cache_file.exists(), "ç¼“å­˜æ–‡ä»¶åº”è¯¥å­˜åœ¨"
            
            with open(cache_file, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
            
            assert len(saved_data) == 50, f"åº”è¯¥ä¿å­˜50æ¡è®°å½•ï¼Œå®é™…ä¿å­˜{len(saved_data)}æ¡"
            assert saved_data[0]['index'] == 0, "ç¬¬ä¸€æ¡è®°å½•ç´¢å¼•åº”è¯¥ä¸º0"
            assert saved_data[49]['index'] == 49, "æœ€åä¸€æ¡è®°å½•ç´¢å¼•åº”è¯¥ä¸º49"
            
            print("âœ… æ­£å¸¸æ“ä½œæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ æ­£å¸¸æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_large_file_operation(self):
        """æµ‹è¯•å¤§æ–‡ä»¶æ“ä½œ"""
        print("\n=== æµ‹è¯•å¤§æ–‡ä»¶æ“ä½œ ===")
        
        cache_file = self.test_dir / "large_test.json"
        cache_data = self.create_test_cache_data(1000)  # 1000æ¡è®°å½•
        project_config = self.create_mock_project_config()
        
        try:
            start_time = time.time()
            await _save_with_safe_write(cache_data, str(cache_file), project_config)
            end_time = time.time()
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨ä¸”å†…å®¹æ­£ç¡®
            assert cache_file.exists(), "å¤§æ–‡ä»¶åº”è¯¥è¢«æˆåŠŸåˆ›å»º"
            
            with open(cache_file, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
            
            assert len(saved_data) == 1000, f"åº”è¯¥ä¿å­˜1000æ¡è®°å½•ï¼Œå®é™…ä¿å­˜{len(saved_data)}æ¡"
            
            file_size = cache_file.stat().st_size
            print(f"âœ… å¤§æ–‡ä»¶æ“ä½œæµ‹è¯•é€šè¿‡ - æ–‡ä»¶å¤§å°: {file_size} bytes, è€—æ—¶: {end_time - start_time:.2f}s")
            return True
            
        except Exception as e:
            print(f"âŒ å¤§æ–‡ä»¶æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_concurrent_write_attempts(self):
        """æµ‹è¯•å¹¶å‘å†™å…¥å°è¯•"""
        print("\n=== æµ‹è¯•å¹¶å‘å†™å…¥ä¿æŠ¤ ===")
        
        cache_file = self.test_dir / "concurrent_test.json"
        cache_data = self.create_test_cache_data(100)
        project_config = self.create_mock_project_config()
        
        async def write_task(task_id):
            """å•ä¸ªå†™å…¥ä»»åŠ¡"""
            try:
                modified_data = [
                    {**item, 'pre_zh': f"{item['pre_zh']}_task{task_id}"}
                    for item in cache_data
                ]
                await _save_with_safe_write(modified_data, str(cache_file), project_config)
                return task_id, True
            except Exception as e:
                return task_id, False
        
        try:
            # å¯åŠ¨å¤šä¸ªå¹¶å‘å†™å…¥ä»»åŠ¡
            tasks = [write_task(i) for i in range(5)]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # éªŒè¯æ–‡ä»¶æœ€ç»ˆå­˜åœ¨ä¸”æœ‰æ•ˆ
            assert cache_file.exists(), "å¹¶å‘å†™å…¥åæ–‡ä»¶åº”è¯¥å­˜åœ¨"
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            is_valid = await DataValidator.validate_json_file(cache_file)
            assert is_valid, "å¹¶å‘å†™å…¥åæ–‡ä»¶åº”è¯¥ä¿æŒæœ‰æ•ˆ"
            
            with open(cache_file, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
            
            assert len(saved_data) == 100, "å¹¶å‘å†™å…¥ååº”è¯¥ä¿æŒæ­£ç¡®çš„è®°å½•æ•°é‡"
            
            successful_tasks = sum(1 for _, success in results if success)
            print(f"âœ… å¹¶å‘å†™å…¥ä¿æŠ¤æµ‹è¯•é€šè¿‡ - {successful_tasks}/5 ä¸ªä»»åŠ¡æˆåŠŸå®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ å¹¶å‘å†™å…¥ä¿æŠ¤æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_disk_space_simulation(self):
        """æ¨¡æ‹Ÿç£ç›˜ç©ºé—´ä¸è¶³æƒ…å†µ"""
        print("\n=== æµ‹è¯•ç£ç›˜ç©ºé—´ä¸è¶³æ¨¡æ‹Ÿ ===")
        
        cache_file = self.test_dir / "disk_space_test.json"
        cache_data = self.create_test_cache_data(100)
        project_config = self.create_mock_project_config()
        
        # åˆ›å»ºä¸€ä¸ªéå¸¸å¤§çš„JSONæ¥æ¨¡æ‹Ÿç£ç›˜ç©ºé—´é—®é¢˜
        large_cache_data = self.create_test_cache_data(10000)
        
        try:
            # é¦–å…ˆåˆ›å»ºä¸€ä¸ªæ­£å¸¸çš„æ–‡ä»¶ä½œä¸ºå¤‡ä»½æµ‹è¯•
            await _save_with_safe_write(cache_data, str(cache_file), project_config)
            original_size = cache_file.stat().st_size
            
            # å°è¯•å†™å…¥å¤§æ–‡ä»¶ï¼ˆå¯èƒ½ä¼šå› ä¸ºç£ç›˜ç©ºé—´å¤±è´¥ï¼Œä½†è¿™æ˜¯é¢„æœŸçš„ï¼‰
            try:
                await _save_with_safe_write(large_cache_data, str(cache_file), project_config)
                print("âœ… å¤§æ–‡ä»¶å†™å…¥æˆåŠŸï¼ˆç£ç›˜ç©ºé—´å……è¶³ï¼‰")
            except Exception:
                # å¦‚æœå†™å…¥å¤±è´¥ï¼ŒéªŒè¯åŸæ–‡ä»¶ä»ç„¶å®Œæ•´
                if cache_file.exists():
                    is_valid = await DataValidator.validate_json_file(cache_file)
                    assert is_valid, "åŸæ–‡ä»¶åº”è¯¥ä¿æŒå®Œæ•´"
                    print("âœ… å†™å…¥å¤±è´¥æ—¶åŸæ–‡ä»¶ä¿æŒå®Œæ•´")
            
            return True
            
        except Exception as e:
            print(f"âŒ ç£ç›˜ç©ºé—´æ¨¡æ‹Ÿæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_backup_and_recovery(self):
        """æµ‹è¯•å¤‡ä»½å’Œæ¢å¤åŠŸèƒ½"""
        print("\n=== æµ‹è¯•å¤‡ä»½å’Œæ¢å¤åŠŸèƒ½ ===")
        
        cache_file = self.test_dir / "backup_test.json"
        original_data = self.create_test_cache_data(50)
        modified_data = self.create_test_cache_data(50)
        for item in modified_data:
            item['pre_zh'] = item['pre_zh'] + "_modified"
        
        project_config = self.create_mock_project_config()
        backup_manager = BackupManager(project_config.getSafeWriteConfig())
        
        try:
            # 1. åˆ›å»ºåŸå§‹æ–‡ä»¶
            await _save_with_safe_write(original_data, str(cache_file), project_config)
            assert cache_file.exists(), "åŸå§‹æ–‡ä»¶åº”è¯¥è¢«åˆ›å»º"
            
            # 2. åˆ›å»ºå¤‡ä»½
            backup_path = await backup_manager.create_backup(cache_file)
            assert backup_path is not None, "å¤‡ä»½åº”è¯¥è¢«åˆ›å»º"
            assert backup_path.exists(), "å¤‡ä»½æ–‡ä»¶åº”è¯¥å­˜åœ¨"
            
            # 3. ä¿®æ”¹åŸå§‹æ–‡ä»¶
            await _save_with_safe_write(modified_data, str(cache_file), project_config)
            
            with open(cache_file, 'r', encoding='utf-8') as f:
                current_data = json.load(f)
            assert current_data[0]['pre_zh'].endswith('_modified'), "æ–‡ä»¶åº”è¯¥è¢«ä¿®æ”¹"
            
            # 4. ä»å¤‡ä»½æ¢å¤
            success = await backup_manager.restore_from_backup(cache_file)
            assert success, "åº”è¯¥èƒ½å¤Ÿä»å¤‡ä»½æ¢å¤"
            
            # 5. éªŒè¯æ¢å¤çš„å†…å®¹
            with open(cache_file, 'r', encoding='utf-8') as f:
                restored_data = json.load(f)
            
            assert not restored_data[0]['pre_zh'].endswith('_modified'), "æ¢å¤åä¸åº”è¯¥åŒ…å«ä¿®æ”¹æ ‡è®°"
            assert len(restored_data) == 50, "æ¢å¤ååº”è¯¥ä¿æŒåŸå§‹è®°å½•æ•°é‡"
            
            print("âœ… å¤‡ä»½å’Œæ¢å¤åŠŸèƒ½æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ å¤‡ä»½å’Œæ¢å¤æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_data_validation_integrity(self):
        """æµ‹è¯•æ•°æ®éªŒè¯å®Œæ•´æ€§"""
        print("\n=== æµ‹è¯•æ•°æ®éªŒè¯å®Œæ•´æ€§ ===")
        
        try:
            # æµ‹è¯•æœ‰æ•ˆæ•°æ®
            valid_file = self.test_dir / "valid_test.json"
            valid_data = self.create_test_cache_data(10)
            
            with open(valid_file, 'w', encoding='utf-8') as f:
                json.dump(valid_data, f, ensure_ascii=False, indent=2)
            
            is_valid = await DataValidator.validate_json_file(valid_file)
            assert is_valid, "æœ‰æ•ˆæ•°æ®åº”è¯¥é€šè¿‡éªŒè¯"
            
            # æµ‹è¯•æ— æ•ˆJSON
            invalid_json_file = self.test_dir / "invalid_json.json"
            with open(invalid_json_file, 'w', encoding='utf-8') as f:
                f.write('{"invalid": json format}')
            
            is_valid = await DataValidator.validate_json_file(invalid_json_file)
            assert not is_valid, "æ— æ•ˆJSONåº”è¯¥å¤±è´¥éªŒè¯"
            
            # æµ‹è¯•ç¼ºå°‘å¿…éœ€å­—æ®µ
            missing_fields_file = self.test_dir / "missing_fields.json"
            incomplete_data = [{"index": 0, "name": "test"}]  # ç¼ºå°‘å¿…éœ€å­—æ®µ
            
            with open(missing_fields_file, 'w', encoding='utf-8') as f:
                json.dump(incomplete_data, f)
            
            is_valid = await DataValidator.validate_json_file(missing_fields_file)
            assert not is_valid, "ç¼ºå°‘å¿…éœ€å­—æ®µçš„æ•°æ®åº”è¯¥å¤±è´¥éªŒè¯"
            
            print("âœ… æ•°æ®éªŒè¯å®Œæ•´æ€§æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®éªŒè¯å®Œæ•´æ€§æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_temp_file_cleanup(self):
        """æµ‹è¯•ä¸´æ—¶æ–‡ä»¶æ¸…ç†"""
        print("\n=== æµ‹è¯•ä¸´æ—¶æ–‡ä»¶æ¸…ç† ===")
        
        cache_file = self.test_dir / "cleanup_test.json"
        cache_data = self.create_test_cache_data(20)
        project_config = self.create_mock_project_config()
        
        try:
            # è®°å½•æ¸…ç†å‰çš„ä¸´æ—¶æ–‡ä»¶
            temp_files_before = list(self.test_dir.glob("*.tmp"))
            
            # æ‰§è¡Œå†™å…¥æ“ä½œ
            await _save_with_safe_write(cache_data, str(cache_file), project_config)
            
            # æ£€æŸ¥æ¸…ç†åçš„ä¸´æ—¶æ–‡ä»¶
            temp_files_after = list(self.test_dir.glob("*.tmp"))
            
            assert len(temp_files_after) == len(temp_files_before), "ä¸´æ—¶æ–‡ä»¶åº”è¯¥è¢«æ¸…ç†"
            assert cache_file.exists(), "ç›®æ ‡æ–‡ä»¶åº”è¯¥å­˜åœ¨"
            
            print("âœ… ä¸´æ—¶æ–‡ä»¶æ¸…ç†æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ ä¸´æ—¶æ–‡ä»¶æ¸…ç†æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_fallback_to_simple_write(self):
        """æµ‹è¯•é™çº§åˆ°ç®€å•å†™å…¥"""
        print("\n=== æµ‹è¯•é™çº§åˆ°ç®€å•å†™å…¥ ===")
        
        cache_file = self.test_dir / "fallback_test.json"
        cache_data = self.create_test_cache_data(30)
        project_config = self.create_mock_project_config(safe_write_enabled=False)
        
        try:
            # ä½¿ç”¨ç¦ç”¨å®‰å…¨å†™å…¥çš„é…ç½®
            from GalTransl.Cache import save_transCache_to_json
            from GalTransl.CSentense import CTransList, CSentense
            
            # åˆ›å»ºæ¨¡æ‹Ÿç¿»è¯‘åˆ—è¡¨
            trans_list = CTransList()
            for i, data in enumerate(cache_data):
                trans = CSentense()
                trans.index = data['index']
                trans.speaker = data['name']
                trans.pre_jp = data['pre_jp']
                trans.post_jp = data['post_jp']
                trans.pre_zh = data['pre_zh']
                trans.proofread_zh = data['proofread_zh']
                trans.trans_by = data['trans_by']
                trans.proofread_by = data['proofread_by']
                trans.trans_conf = data['trans_conf']
                trans.doub_content = data['doub_content']
                trans.unknown_proper_noun = data['unknown_proper_noun']
                trans.problem = ""
                trans.post_zh = data['pre_zh']
                trans_list.append(trans)
            
            await save_transCache_to_json(trans_list, str(cache_file), 
                                          post_save=False, project_config=project_config)
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨ä¸”å†…å®¹æ­£ç¡®
            assert cache_file.exists(), "é™çº§å†™å…¥åæ–‡ä»¶åº”è¯¥å­˜åœ¨"
            
            with open(cache_file, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
            
            assert len(saved_data) == 30, "é™çº§å†™å…¥åº”è¯¥ä¿å­˜æ‰€æœ‰æ•°æ®"
            
            print("âœ… é™çº§åˆ°ç®€å•å†™å…¥æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ é™çº§åˆ°ç®€å•å†™å…¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"""
        print("ğŸš€ å¼€å§‹å®‰å…¨å†™å…¥æœºåˆ¶é›†æˆæµ‹è¯•")
        print("=" * 50)
        
        await self.setup()
        
        test_methods = [
            self.test_normal_operation,
            self.test_large_file_operation,
            self.test_concurrent_write_attempts,
            self.test_disk_space_simulation,
            self.test_backup_and_recovery,
            self.test_data_validation_integrity,
            self.test_temp_file_cleanup,
            self.test_fallback_to_simple_write
        ]
        
        passed = 0
        total = len(test_methods)
        
        for test_method in test_methods:
            try:
                result = await test_method()
                if result:
                    passed += 1
                self.results.append((test_method.__name__, result))
            except Exception as e:
                print(f"âŒ æµ‹è¯• {test_method.__name__} å‘ç”Ÿå¼‚å¸¸: {e}")
                self.results.append((test_method.__name__, False))
        
        await self.teardown()
        
        # æ‰“å°æµ‹è¯•ç»“æœæ‘˜è¦
        print("\n" + "=" * 50)
        print("ğŸ é›†æˆæµ‹è¯•ç»“æœæ‘˜è¦")
        print("=" * 50)
        
        for test_name, result in self.results:
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{test_name}: {status}")
        
        print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
        success_rate = (passed / total) * 100
        print(f"æˆåŠŸç‡: {success_rate:.1f}%")
        
        if success_rate >= 80:
            print("ğŸ‰ é›†æˆæµ‹è¯•åŸºæœ¬é€šè¿‡ï¼å®‰å…¨å†™å…¥æœºåˆ¶è¿è¡Œè‰¯å¥½ã€‚")
        elif success_rate >= 60:
            print("âš ï¸ é›†æˆæµ‹è¯•éƒ¨åˆ†é€šè¿‡ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚")
        else:
            print("ğŸš¨ é›†æˆæµ‹è¯•å¤±è´¥ç‡è¾ƒé«˜ï¼Œéœ€è¦ä¿®å¤å…³é”®é—®é¢˜ã€‚")
        
        return success_rate >= 80


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    test_suite = IntegrationTestSuite()
    success = await test_suite.run_all_tests()
    return success


if __name__ == '__main__':
    # è¿è¡Œé›†æˆæµ‹è¯•
    result = asyncio.run(main())
    exit_code = 0 if result else 1
    exit(exit_code)